{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['olid_taska', 'olid_taskb', 'olid_taskc', 'abuseval', 'anatomy_of_hate', 'davidson', 'dynabench_label', 'dynabench_type', 'hatexplain_label', 'hatexplain_target', 'latent_hatred_labels', 'latent_hatred_implicit_class', 'stormfront', 'waseem', 'founta', 'gab', 'hasoc_english_task_1', 'hasoc_english_task_2', 'offenseval', 'toxigen_group', 'toxigen_label'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../Data/prepared_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in config.keys():\n",
    "    data = load_custom_ds(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_use = ['olid_taska', 'waseem', 'founta', 'davidson', 'dynabench_label', 'hatexplain_label', 'toxigen_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"hateData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all pairs of data\n",
    "import os\n",
    "import pandas\n",
    "for i in range(len(ds_to_use)):\n",
    "    for j in range(i+1, len(ds_to_use)):\n",
    "        # make dir for this pair\n",
    "        dir_name = ds_to_use[i] + \"_AND_\" + ds_to_use[j]\n",
    "        if not os.path.exists(BASE_PATH + dir_name):\n",
    "            os.mkdir(BASE_PATH + dir_name)\n",
    "        # Create sub dirs with dataset names\n",
    "        if not os.path.exists(BASE_PATH + dir_name + \"/\" + ds_to_use[i]):\n",
    "            os.mkdir(BASE_PATH + dir_name + \"/\" + ds_to_use[i])\n",
    "        if not os.path.exists(BASE_PATH + dir_name + \"/\" + ds_to_use[j]):\n",
    "            os.mkdir(BASE_PATH + dir_name + \"/\" + ds_to_use[j])\n",
    "        # load data\n",
    "        data1_train, data1_val, data1_test = load_custom_ds(ds_to_use[i])\n",
    "        data2_train, data2_val, data2_test = load_custom_ds(ds_to_use[j])\n",
    "        # drop NA\n",
    "        data1_train = data1_train.dropna()\n",
    "        data1_val = data1_val.dropna()\n",
    "        data1_test = data1_test.dropna()\n",
    "        data2_train = data2_train.dropna()\n",
    "        data2_val = data2_val.dropna()\n",
    "        data2_test = data2_test.dropna()\n",
    "        data_1_text = data1_train['text'].tolist() + data1_val['text'].tolist() + data1_test['text'].tolist()\n",
    "        data_2_text = data2_train['text'].tolist() + data2_val['text'].tolist() + data2_test['text'].tolist()\n",
    "        # write each daat point into a txt file\n",
    "        for idx, text in enumerate(data_1_text):\n",
    "            with open(BASE_PATH + dir_name + \"/\" + ds_to_use[i] + \"/\" + str(idx) + \".txt\", \"w\") as f:\n",
    "                f.write(text)\n",
    "        for idx, text in enumerate(data_2_text):\n",
    "            with open(BASE_PATH + dir_name + \"/\" + ds_to_use[j] + \"/\" + str(idx) + \".txt\", \"w\") as f:\n",
    "                f.write(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb7536a7868e838a44bd6ffd392d812ea366d91edf5c9bb10c05e095f5d3fdbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
